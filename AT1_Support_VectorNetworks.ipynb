{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AT1_Support-VectorNetworks.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DonaldTurton/UTS_ML2019_ID13304086/blob/master/AT1_Support_VectorNetworks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6UbeKQGdy21",
        "colab_type": "text"
      },
      "source": [
        "Donald Turton #13304086\n",
        "\n",
        "Advanced Data Analytics Algorithms \n",
        "\n",
        "Due Date: 28 Aug 2019\n",
        "\n",
        "\n",
        "GitHub Repo: https://github.com/DonaldTurton/UTS_ML2019_ID13304086\n",
        "\n",
        "Colab Notebook: https://colab.research.google.com/github/DonaldTurton/UTS_ML2019_ID13304086/blob/master/AT1_Support_VectorNetworks.ipynb#scrollTo=UsP2oRslgr0s\n",
        "\n",
        "\n",
        "#Assignment 1: Understanding the Literature \"Support-Vector Networks\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bunwOGoKd6kv",
        "colab_type": "text"
      },
      "source": [
        "##Introduction:\n",
        "\n",
        "The following report is an analysis of the paper \"Support-Vector Networks\" by Corina Cortes and Vladimir Vapnik written in 1995. This report contains a brief explanation of the model proposed by the authors; an analysis of the innovation that characterized this new model; an analysis of the technical quality; some examples of the application; and constructive criticism of how the paper is presented.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDrMx9n4gRQD",
        "colab_type": "text"
      },
      "source": [
        "## Content:\n",
        "Corina Cortes and Vladimir Vapnik propose a new type of learning machine for their time, the so-called \"Support-Vector Networks\". This is a two-group classification model, which objective is to find the optimal boundary or “Hyperplane” capable of separating the training data into their respective groups without errors (or minimizing it). They also introduced the concept of the “Soft Margins” which allows the generalizability of the model and lastly, the model is tested against other learning machines. \n",
        "\n",
        "A new way to construct the decision function is developed, in which the authors demonstrate how to obtain an optimal hyperplane which minimizes the function, this optimal hyperplane is calculated by solving a quadratic programming problem. The model is based on the alteration of the order in which the function was calculated before, introducing the \"convulation of the dot product\". This enables the construction of the decision boundary in a high dimensional space, where the separation of the data becomes easier than in the original dimension space, allowing the adaptability of the model to many data distributions. \n",
        "\n",
        "As an extension to the model, the paper introduces the concept of the \"Soft Margins” concept, which enhances the generalizability of the model for the cases where is not possible to separate the training data without error, making this model as powerful as the Neural Networks. \n",
        "\n",
        "The research demonstrates the usage of this model and its performance. The model is tested and compared against human performance and different well know learning algorithms such as linear classifiers, k-nearest neighbours and Neural Networks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsP2oRslgr0s",
        "colab_type": "text"
      },
      "source": [
        "## Innovation: \n",
        "The creative idea provided by the model proposed by Cortes and Vapnik is the introduction of the Support Vector Networks which are possible by construction of the Hyperplane by using the support vectors. The idea of taking the solution surface to a high dimensional space by the implementation of the Convolution of the Dot Product and the extension of the model with the introduction of the Soft Margins, which allows the generalizability of the model to the cases where is impossible the separation of the train set. A brief explanation below. \n",
        "\n",
        "\n",
        "This model was able to perform better than the other algorithms by mapping the input vector into a high dimensional feature space, where a OPTIMAL linear decision surface is constructed called “Optimal Hyperplane”. This decision surface maximizes the distance between the two classes, which are delimitated by margins. These margins are constructed using some points “Training Data” which are called “Support Vectors” \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j225l8NkpDFx",
        "colab_type": "text"
      },
      "source": [
        "*It's interesting to note that it still the same concept proposed by Fisher in 1936, of using a linear decision surface for pattern recognition.*\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCpD5xS-pE8F",
        "colab_type": "text"
      },
      "source": [
        "To be able to create these new learning machines, Cortes and Vapnik had to solve 2 issues that aroused around the concept. These solutions are the concepts that make this model so innovative. A brief explanation and the evolution of the model below. \n",
        "\n",
        "1. How to find a separating hyperplane capable of generalizing well for the rest of the data?  \n",
        "2. How to treat a space with so many dimensions?\n",
        "\n",
        "The generalizability of the hyperplane was solved by Vapnik in 1965. He proposed taking a small amount of data for training and finding a hyperplane capable of separate the observations without error, Vapnik called this training data “Support Vectors\".  The expected probability of error for the test sample can be calculated using the number of training vectors and expected value of support vectors (Figure1).  This fact is what enables the ability to generalize the separation. The model states that if it's possible to construct a Hyperplane with relatively small amount of support vectors (compared to the training set), then it is possible to generalize the separation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LiIT8KeoALh",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        ">  Figure 1. Expected Probability of error in Test Sample (Cortes & Vapnik 1995).\n",
        "\n",
        "<img src=\"https://github.com/DonaldTurton/UTS_ML2019_ID13304086/blob/master/proberror.png?raw=TRUE\" width=\"500\"/>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr-oe3JsoKLN",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "The problem of the dimensions was solved by changing the order in which the model makes the decision. The proposed model first compares two vectors in the input space which the result is then transformed (nonlinearly) to determine the output. This characteristic is what enables the model to construct many different types of classification boundary, with the ability to adapt to the data set by taking a polynomial shape. The paper provides a good visual explanation of this concept (Figure 2).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzlwNdt1oPGg",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> Figure 2. Process of classification with support vectors (Cortes & Vapnik 1995).\n",
        "\n",
        "<img src=\"https://github.com/DonaldTurton/UTS_ML2019_ID13304086/blob/master/supportvector.png?raw=TRUE\" width=\"500\"/>\n",
        "\n",
        "\n",
        "One of the most innovative characteristics of the proposed model, it’s the way in which the mode can perform even in the scenario where it’s impossible to separate the training vectors without error. To make this possible, the concept of the SOFT MARGIN HYPERPLANE was introduced. The idea is to find a Hyperplane that allows having errors in the separation but minimizes these errors as much as possible. This extension is the characteristic that enables the model to perform in any data set which makes the model to be considered a new learning algorithm and to perform as good as the Neural Networks.\n",
        "\n",
        "Corina Cortes and Vladimir Vapnik test their propose model by comparing the results with previous work done by Leon Bottou. Bottou’s research consisted of handwriting digit recognition, where the performance of several different classifier algorithms are compared (Bottou et al. 1994).\n",
        "\n",
        "\n",
        "The \"Support-Vector Network\" was set to perform the same task, with the same data sets as the models compared by Bottou. Cortes and Vapnik were able to demonstrate how these Support-Vector Networks are able to perform better than a more complex model, such as the \"LeNet 4\", a Neural Network in Bottou benchmark, which was considered the most powerful learning algorithm at that time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "no1meqn_hCtc",
        "colab_type": "text"
      },
      "source": [
        "## Technical Quality:\n",
        "\n",
        "The research seems to have adequate implementation and testing. The Support-Vector Network stated in this paper is tested using the same data sets as the models used for benchmark in Bottou’s research paper. The databases used for testing the models are US postal services Database and NIST database.\n",
        "\n",
        "The US Postal Service data set was used to measure the performance of polynomials of different degrees (1 to 7), and then compared the performance of different classification \"machines\" like Humans, Decision Tree CART, Decision Tree C4.5, 2-Layer Neural Network and 5-Layer Network \"LeNet1\". The authors clarify the complexity of the data to be solved by the Support-Vector Network because of the impossibility of separate the training data.\n",
        "\n",
        "Some irregularities were detected in the way in which the results of the models are compared. The parameter used to compare the performance is the \"Raw error %\", which seems to represent the number of misclassifications for each model. However, the paper is not clear about which errors are being compared.  The errors provided from the research performed by Bottou does not include a specification about their precedence (Train or Test set). If we look at the results provided in the original publication, LeNet1 TEST error is 1.7 and the error provided in for the comparison is 5.1(LeCun et al. 1995). This evidence suggests the error shown in Cortes and Vapnik research is obtained from the performance of the models in the Train Set, which is being compared with the error reported for the polynomial classifiers, clearly stated to be from the train set.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCe7LQJPniF8",
        "colab_type": "text"
      },
      "source": [
        "*Note: Yann LeCun 1995 paper was used to get the figures since the original Bottou Paper found did not contain the proper figures.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRjn9lIinjKX",
        "colab_type": "text"
      },
      "source": [
        ">Figure 3. Error rate on test set (LeCun et al. 1995).\n",
        "\n",
        "<img src=\"https://github.com/DonaldTurton/UTS_ML2019_ID13304086/blob/master/error_rate_LeCun.png?raw=TRUE\" width=\"500\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LUTP0bFpQ29",
        "colab_type": "text"
      },
      "source": [
        "Assuming that the previous postulate is correct, it would be better to compare the performance of the models in their Test Set, since that’s the main way in which a model can demonstrate its ability to perform. \n",
        "\n",
        "The NIST database was used to measure the performance of a 4th-degree polynomial classifier and suggests a comparison with the other classification models. For this section, there is a table with the reported errors for the Support-Vector Network in train and test sets, which is later compared to the Test Error from the other models. This approach resembles to be more reliable and easier to follow than the past data set model comparison.  \n",
        "\n",
        "The paper states that in the worst-case scenario, the polynomial classifier training time was faster than the best performance Neural Network. However, the paper does not provide any other way to compare the performance of the models. Other researchers have reported in their papers training time, recognition time and memory requirements as parameters to compare models, like Y.LeCun handwriting comparison paper (Figure 4 and 5) (LeCun et al. 1995).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcQ_Q4u9pTEx",
        "colab_type": "text"
      },
      "source": [
        "> Figure 4. Time required for recognition of a single character in milliseconds (LeCun et al. 1995).\n",
        "\n",
        "<img src=\"https://github.com/DonaldTurton/UTS_ML2019_ID13304086/blob/master/Time_recogn.png?raw=TRUE\" width=\"500\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI1ruVoKpucf",
        "colab_type": "text"
      },
      "source": [
        "> Figure 5. Memory requirements for classifications on Test Patterns (LeCun et al. 1995).\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/DonaldTurton/UTS_ML2019_ID13304086/blob/master/Memory.png?raw=TRUE\" width=\"500\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOqNUjzIqNFK",
        "colab_type": "text"
      },
      "source": [
        "## Application and X Factor:\n",
        "\n",
        "The application of the model implemented in the report is for the recognition of handwritten digits. This application was probably chosen to enable the possibility of comparing the performance of the SVM with different learning algorithms already studied and compared in other papers, which are used as a benchmark.  \n",
        "\n",
        "Nowadays, \"Support Vector Machines\" are used to solve several different types of classification and regression problems like Face detection, text categorization, image classification, bioinformatics and handwriting recognition (Dataflair Team 2018).\n",
        "\n",
        "Bioinformatics attracted a lot of attention for Support Vector Machine implementation, where cancer diagnosis can be performed by applying microarray technology capable of extracting characteristics in the molecular level of the DNA (Wang 2005). Another interesting application is in financial time series forecasting, where SVMs are more likely to perform better than ARIMA model, because of its high generalization ability, which enables a low chance of overfitting (Kim 2003; Tay & Cao 2001).\n",
        "\n",
        "In my opinion, this research could be improved by testing the proposed model in many different types of problems and data sets, where the performance of the model could be compared (error, time, memory and others) with other models. This would allow us to get a better understanding of the strength and weaknesses of each model, and to be able to make a wiser decision when choosing a model to use for any specific situation. For further research, it would be interesting to see an explanation or tutorial on how this model can be replicated in a programming language, allowing readers to interact with the model and test it.\n",
        "\n",
        "I have found Cortes and Vapnik paper interesting because it explains the process of how learning machines have been evolving for decades. Before reading this paper, I thought these learning machines were a recent discovery which came as a result of the technology. However, now I understand the process, all the research and small steps that were necessary to allow learning machines to be what they are nowadays. Technology has only permitted humans to continue expanding the capability of their mathematical models, but the machines would be incapable of doing anything without the knowledge and complex ability of construction from humans.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXPXJIjCqV5h",
        "colab_type": "text"
      },
      "source": [
        "## Presentation:\n",
        "I have found this paper well structured, it allows the reader to follow a chronological timeline of the creation of this model which permits a good understanding of the development of the model and the circumstances in which every progression was made. The paper demonstrates the role of technology to achieve each improvement.\n",
        "\n",
        "In my opinion, there are some improvements that could be made to enhance the comprehension of the paper. The presentation of the comparison of the proposed model with the benchmark is not easy to understand. Also, the results of the \"Raw error %\" are hard to interpret, it is not clear if raw error means the number of misclassified observation (Raw) or if it’s a percentage of errors (%). Regarding the US Postal Service data set, is not clear if the paper is comparing the results of training or test sets. \n",
        "\n",
        "From another perspective, the paper does provide examples of the observations that were misclassified by the model. This allows the reader to understand the complexity of the input image provided, which in some cases would be hard to classify, even for humans.   \n",
        "\n",
        "The technical level of the paper was pretty high which made the reading a bit dense, this is understandable because of the complexity of the model and the need to use the pages in the most efficient way. Reason why background reading and YouTube videos of explanations were needed to fully understand the concept. Once the mathematical background was understood, the reading of this paper was easier and more engaging.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A77TLgbfqZ4k",
        "colab_type": "text"
      },
      "source": [
        "## References: \n",
        "*Bottou, L., Cortes, C., Denker, J.S., Drucker, H., Guyon, I., Jackel, L.D., LeCun, Y., Müller, U.A., Säckinger, E. & Simard, P.Y. 1994, 'Comparison of classifier methods: a case study in handwritten digit recognition', , pp. 77.*\n",
        "\n",
        "*Cortes, C. & Vapnik, V. 1995, 'Support-vector networks', Machine Learning, vol. 20, no. 3, pp. 273-97.*\n",
        "\n",
        "*Dataflair Team 2018, Real-Life Applications of SVM (Support Vector Machines), viewed 17 Aug, 2019, <https://data-flair.training/blogs/applications-of-svm/>.*\n",
        "\n",
        "*Goldstain, M. 2014, The Dot Product and Convulation, viewed Michael <https://jallen.faculty.arizona.edu/sites/jallen.faculty.arizona.edu/files/Chapter_10_Dot_product_and_Convolution.pdf>.*\n",
        "\n",
        "*Kim, K. 2003, 'Financial time series forecasting using support vector machines', Neurocomputing, vol. 55, no. 1, pp. 307-19.*\n",
        "\n",
        "*LeCun, Y., Jackel, L.D., Bottou, L., Brunot, A., Cortes, C., Denker, J.S., Drucker, H., Guyon, I., Muller, U.A. & Sackinger, E. 1995, 'Comparison of learning algorithms for handwritten digit recognition', vol. 60, pp. 53-60.*\n",
        "\n",
        "*Tay, F.E.H. & Cao, L. 2001, 'Application of support vector machines in financial time series forecasting', Omega, vol. 29, no. 4, pp. 309-17.*\n",
        "\n",
        "*Tsang, S. 2019, 'Review: LeNet-1, LeNet-4, LeNet-5, Boosted LeNet-4 (Image Classification)', Medium, viewed Aug 14, 2019, <https://medium.com/@sh.tsang/paper-brief-review-of-lenet-1-lenet-4-lenet-5-boosted-lenet-4-image-classification-1f5f809dbf17>.*\n",
        "\n",
        "*Wang, L. 2005, Support Vector Machines:\n",
        "Theory and Applications, Springer, Berlin.*\n",
        "\n"
      ]
    }
  ]
}